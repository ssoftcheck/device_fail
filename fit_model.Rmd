---
title: "R Notebook"
output:
  html_notebook: default
  html_document: default
---

```{r setup, include=FALSE}
library(data.table)
library(ggplot2)
library(xgboost)
library(foreach)
library(doSNOW)
library(iterators)
library(pdp)
library(tcltk)
library(DMwR)
library(ROCR)

phi = function(a,p,cutoff=0.5) {
  po = prediction(p,a)
  perf = performance(po,measure = "phi")
  point = which.min(abs(perf@x.values[[1]]-cutoff))[1]
  return(perf@y.values[[1]][point])
}
auc = function(a,p) {
  po = prediction(p,a)
  perf = performance(po,measure = "auc")
  return(perf@y.values[[1]])
}
accuracy = function(a,p,cutoff=0.5) {
  po = prediction(p,a)
  perf = performance(po,measure = "acc")
  point = which.min(abs(perf@x.values[[1]]-cutoff))[1]
  return(perf@y.values[[1]][point])
}
sensitivity = function(a,p,cutoff=0.5) {
  po = prediction(p,a)
  perf = performance(po,measure = "sens")
  point = which.min(abs(perf@x.values[[1]]-cutoff))[1]
  return(perf@y.values[[1]][point])
}
specificity = function(a,p,cutoff=0.5) {
  po = prediction(p,a)
  perf = performance(po,measure = "spec")
  point = which.min(abs(perf@x.values[[1]]-cutoff))[1]
  return(perf@y.values[[1]][point])
}

sense.xgb = function(preds, dtrain) {
  labels = getinfo(dtrain, "label")
  val = sensitivity(labels,preds,0.5)
  return(list(metric = "sensitivity", value = val))
}

balacc.xgb = function(preds,dtrain) {
  labels = getinfo(dtrain, "label")
  sens = sensitivity(labels,preds,0.5)
  spec = specificity(labels,preds,0.5)
  val = (sens+spec)/2
  return(list(metric = "bal_acc", value = val))
}

readData = function(x,filterTime=-1) {
  # filter days to save time/space
  d=fread(x)
  d[,timestamp:=lubridate::ymd_hms(timestamp)]
  d = d[order(termination_point,timestamp)]
  if(filterTime > 0) {
    failtime = min(d[fail==1,timestamp])
    if(!is.na(failtime))
      d = d[difftime(failtime,timestamp,units="hours") < filterTime]
  }
  return(d)
}
```

```{r}
# for summarizing missing fields

# tp.folders = grep("h\\_",list.dirs("./data/"),value=TRUE)
# for(each in tp.folders) {
#   tempds = Reduce(function(a,b) rbind(a,b,fill=TRUE),Map(readData,list.files(each,full.names = TRUE)))
#   missing = tempds[,lapply(.SD,function(x) mean(is.na(x))),.SDcols=setdiff(names(tempds),"node_id"),by=node_id]
#   fwrite(missing,paste0(each,"/",strsplit(each,"//")[[1]][2],"_missing.csv"))
#   rm(missing,tempds)
# }
```


```{r}
# read data, replace h_OCHCTP with a whatever terminatin point you like
files = grep("/h_OCHCTP\\_(?!changepoint).+csv$",list.files("C:/device failures/failure_files",full.names=TRUE),value=TRUE,perl = TRUE)
ds = Reduce(function(a,b) rbind(a,b,fill=TRUE),Map(readData,files))
ds[,fail:=factor(fail)]
```


```{r}
# specify predictor variables
nodes = ds[,unique(node_id)]
vars = c(
"BerPreFecAve",
"BerPreFecMax",
"BerPreFecMin",
"ChanOchChromaticDispersionAve",
"ChanOchChromaticDispersionMax",
"ChanOchChromaticDispersionMin",
"ChanOchLBCAve",
"ChanOchLBCMax",
"ChanOchLBCMin",
"ChanOchOptAve",
"ChanOchOptMax",
"ChanOchOptMin",
"PmType",
"PmdAve",
"PmdMax",
"PmdMin",
"Qave",
"Qmax",
"Qmin",
"SoPmdAve",
"SoPmdMax",
"SoPmdMin"
)
var.formula = as.formula(paste0("fail~",paste(vars,collapse="+")))
```

```{r}
# create lag variables and add to predictor set
interval = 4 # 1 hour
lags = 24 # 1 day
l = seq(interval,lags,interval)
for(v in vars) {
  newvars = paste0(v,"_lag",l)
  ds[,(newvars) := shift(get(v),l),by=.(node_id,termination_point)]
  var.formula = update(var.formula,paste(c("~.",newvars),collapse="+"))
  vars = union(vars,newvars)
}
```

```{r}
# make folds
set.seed(5)
ds[,fold := sample(1:10,nrow(ds),replace=TRUE)]
ds[,mean(as.integer(fail)-1),fold][order(fold)]
```


```{r}
# evaluate parameters with cross validation
params = expand.grid(objective="binary:logistic",subsample=c(0.5,0.7,0.9),max.depth=c(2,4,8),eta=c(0.001,0.01),min.child.weight=c(1,2,3),colsample.bytree=c(0.5,0.7,0.9),stringsAsFactors = FALSE,KEEP.OUT.ATTRS = FALSE)
params = as.data.table(params)

cl = makeCluster(4)
registerDoSNOW(cl)
opts = list(progress=function(incr) setTkProgressBar(pb,value = incr,label=sprintf("%3.2f%%",100*incr/nrow(params))))

perf.final = foreach(cvf = min(ds$fold):max(ds$fold),.combine="rbind",.multicombine=TRUE) %do% {
  trainset = which(ds[,fold] != cvf)
  testset = which(ds[,fold] == cvf)
  
  train = SMOTE(var.formula,data=ds[trainset,c("fail",vars),with=FALSE],perc.over = 5000,perc.under = 100)
  
  cat("Fold ",cvf,"\n")
  cat("old event rate: ",ds[trainset,mean(as.integer(fail)-1)],"\n")
  cat("new event rate: ",train[,mean(as.integer(fail)-1)],"\n")

  train = xgb.DMatrix(as.matrix(train[,vars,with=FALSE]),label = as.integer(train[,fail])-1)
  test = xgb.DMatrix(as.matrix(ds[testset,vars,with=FALSE]),label = as.integer(ds[testset,fail])-1)
  xgb.DMatrix.save(train,"train.matrix")
  xgb.DMatrix.save(test,"test.matrix")
  rm(train,test)
  
  pb = tkProgressBar(min = 0,max=max(ds$fold),title =paste("Progress Fold",cvf),label = "0%")
  result = foreach(pnow=iter(params,by="row"),.combine="rbind",.packages=c("xgboost","data.table","ROCR"),.multicombine=TRUE,.options.snow=opts) %dopar% {
    fit = xgb.train(data=xgb.DMatrix("train.matrix"),nrounds=1000,save_period=NULL,params=as.list(pnow),verbose=0)
    test = xgb.DMatrix("test.matrix")
    perf = lapply(seq(100,1000,100),function(ntree) {
      pred = predict(fit,test,ntreelimit = ntree)
      assess = lapply(seq(0.1,0.9,0.1),function(cut) lapply(list(data.table(a=ds[testset,fail],p=pred)),function(x) {
        data.table(fold=cvf,ntree=ntree,cutoff=cut,auc=auc(x$a,x$p),phi=phi(x$a,x$p,cut),acc=accuracy(x$a,x$p,cut),sens=sensitivity(x$a,x$p,cut),spec=specificity(x$a,x$p,cut))
        })[[1]])
      return(rbindlist(assess))
    })
    return(rbindlist(perf))
  }
  file.remove(c("train.matrix","test.matrix"))
  close(pb)
  return(result)
}
stopCluster(cl)
```

```{r}
# summarize results across validation folds
perf.summary = cbind(params[rep(1:nrow(params),times=max(ds$fold),each=9*10)],perf.final)
perf.summary[,balacc:= (sens+spec)/2]
perf.summary = perf.summary[,lapply(.SD,mean),by=c(names(params),"ntree","cutoff"),.SDcols=c("auc","phi","acc","sens","spec","balacc")]
save(perf.final,perf.summary,file="perf.summary.rdata")
```

```{r}
# univariate plots of performance metric across parameters, change y value to metric of choice
plotvars = c("subsample","max.depth","eta","min.child.weight","colsample.bytree","ntree","cutoff")
# plotvars = combn(plotvars,2)
for(i in plotvars) {
  plt = ggplot() + aes(x=factor(perf.summary[[i]]),y=perf.summary$balacc) + geom_boxplot() + xlab(i) + ylab("balanced accuracy")
  print(plt)
  rm(plt)
}
```

```{r}
# train final model. save training data and final model fit
set.seed(5)
train = SMOTE(var.formula,data=ds[,c("fail",vars),with=FALSE],perc.over = 5000,perc.under = 100)
save(train,file="full_train.rdata")
train = xgb.DMatrix(as.matrix(train[,vars,with=FALSE]),label = as.integer(train[,fail])-1)
full.fit = xgb.train(data=train,nrounds=1000,save_period=NULL,params=list(objective="binary:logistic",
                                                                          subsample=0.5,
                                                                          max.depth=8,
                                                                          eta=0.01,
                                                                          min.child.weight=1,
                                                                          colsample.bytree=0.5))
xgb.save(full.fit,"full_fit.xgb")
ds[,pred := predict(full.fit,xgb.DMatrix(as.matrix(ds[,vars,with=FALSE])))]
```

```{r}
# top N variable importance 
full.imp = xgb.importance(feature_names = vars,model=full.fit)
xgb.ggplot.importance(importance_matrix = full.imp,top_n = 10)
```

```{r}
# density plots of top 1:N features
top = full.imp[1:15,Feature]
temp = melt(ds,id.vars="fail",measure.vars = top)[!is.na(value)]
limits = temp[,.(low=quantile(value,0.01),high=quantile(value,0.99)),by="variable"]
temp = merge(temp,limits,by="variable",all.x = TRUE,all.y=FALSE)[value > low & value < high]
for(i in unique(temp$variable))
  print(ggplot(temp[variable==i]) + aes(x=value,fill=fail) + geom_density(alpha=0.8) + ggtitle(i))
rm(temp)
```

```{r}
# create partial dependence 
vp = train[,lapply(.SD,function(x) quantile(x,c(0.02,seq(0.1,0.9,0.1),0.98),na.rm=TRUE)),.SDcols=top]

opts = list(progress=function(incr) setTkProgressBar(pb,value = incr,label=sprintf("%3.2f%%",100*incr/length(top))))
pb = tkProgressBar(min = 0,max=length(top),title = "Progress",label = "0%")

cl = makeCluster(4)
registerDoSNOW(cl)
pd = foreach(x = names(vp),.packages=c("data.table","xgboost","pdp"),.options.snow=opts) %dopar% {
  # setTkProgressBar(pb,value=which(names(vp)==x),label = sprintf("%3.2f%%",100*which(names(vp)==x)/ncol(vp)))
  partial(object = full.fit,pred.var=x,pred.grid = vp[,x,with=FALSE],chull=TRUE,prob=TRUE,train=train[,setdiff(names(train),"fail"),with=FALSE],plot=FALSE)
}
names(pd) = top
stopCluster(cl)
close(pb)
```


```{r}
# plot partial dependence
pdf("h_OCHCTP top 15 parital dependence plots.pdf")
for(i in names(pd))
  print(ggplot(pd[[i]]) + aes_string(x=i,y="yhat") + geom_point() + geom_line() + geom_smooth() + ylab("Failure Probability"))
dev.off()
```

```{r}
# plot predicted probabilities over time leading to failure
hasfail = ds[fail==1,.(start=min(timestamp)),by=.(node_id,termination_point)]
pdf("h_OCHCTP failure prediction over time.pdf")
for(i in 1:nrow(hasfail)) {
  plt = ggplot(ds[termination_point==hasfail[i,termination_point] & node_id==hasfail[i,node_id] & 
              difftime(hasfail[i,start],timestamp,units="hours") <= 24 & difftime(hasfail[i,start],timestamp,units="hours") >= -4]) + 
    aes(x=timestamp,y=pred) + geom_point() + geom_line() + geom_vline(xintercept=as.numeric(hasfail[i,start]),lty=2,color="red",size=2) + geom_smooth(method="loess") + 
    scale_y_continuous(limits = c(0,1)) +
    xlab("Time") + ylab("Failure Probability") + ggtitle(paste0("Node ",gsub("(.+)@(.+)","\\1",hasfail[i,node_id]),"\n","Termination Point ",hasfail[i,termination_point]))
  print(plt)
}
dev.off()
```


```{r}
# code to read console output that was sent to file (via sink funciton) of xgb.train function's watchlist data sets, i.e. use to track a metric from a watchlist over iterations of fitting

# prog = Reduce(c,Map(readLines,grep("progress\\_",list.files(),value = TRUE)))
# prog = regmatches(prog,regexec("(.+)@.+|Train-\\w+:([\\d\\.]+)\tTest-\\w+:([\\d\\.]+)",prog,perl=TRUE))
# prog = Reduce(rbind,Map(function(x) c(Node=x[2],Train=x[3],Test=x[4]),prog))
# prog = as.data.table(prog)
# prog[,c("Train","Test") := lapply(.SD,as.numeric),.SDcols=c("Train","Test")]
# prog = prog[apply(prog,1,function(x) !all(is.na(x)))]
# # extend node name
# ind = which(prog$Node != "")
# ind = cbind(ind,c(ind[-1]-1,nrow(prog)))
# for(i in 1:nrow(ind)) {
#   prog[ind[i,1]:ind[i,2],Node := prog[ind[i,1],Node]]
# }
# prog = prog[!(is.na(Train) & is.na(Test))]
# prog[,Step:=1:.N,by=Node]
```



